<div align="center">

<h1>ğŸ¤– knowlyr-agent</h1>

<p><strong>Agent è½¨è¿¹æ•°æ®å·¥ç¨‹ Monorepo â€” æ‰§è¡Œã€å½•åˆ¶ã€è¯„åˆ†ã€ç¼–æ’ä¸€ç«™å¼ Pipeline</strong><br/>
<em>Agent trajectory data engineering monorepo â€” sandbox execution, trajectory recording, process reward scoring & pipeline orchestration</em></p>

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
<br/>
[![CI](https://github.com/liuxiaotong/knowlyr-agent/actions/workflows/ci.yml/badge.svg)](https://github.com/liuxiaotong/knowlyr-agent/actions/workflows/ci.yml)
[![Tests](https://img.shields.io/badge/tests-444_passed-brightgreen.svg)](#å¼€å‘)
[![MCP](https://img.shields.io/badge/MCP-16_Tools-purple.svg)](#mcp-server)
[![Packages](https://img.shields.io/badge/packages-5-orange.svg)](#å­åŒ…ä¸€è§ˆ)

[å­åŒ…ä¸€è§ˆ](#å­åŒ…ä¸€è§ˆ) Â· [æ¶æ„](#æ¶æ„) Â· [å®‰è£…](#å®‰è£…) Â· [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹) Â· [Gym-Style API](#gym-style-api) Â· [å¤šé¢†åŸŸæ”¯æŒ](#å¤šé¢†åŸŸæ”¯æŒ) Â· [MCP Server](#mcp-server) Â· [å¼€å‘](#å¼€å‘) Â· [ç”Ÿæ€](#data-pipeline-ç”Ÿæ€)

</div>

---

> ğŸ¯ **5 åŒ… Monorepo** core Â· sandbox Â· recorder Â· reward Â· hubï¼Œç‹¬ç«‹å®‰è£…ã€ç‹¬ç«‹ MCP
> ğŸ‹ï¸ **Gym-Style API** AgentEnv / TimeStep / Wrapper / Registryï¼Œå…¼å®¹ Gymnasium ç”Ÿæ€
> ğŸŒ **å¤šé¢†åŸŸæ”¯æŒ** Coding Â· Browser Â· è‡ªå®šä¹‰ DomainProfileï¼Œå£°æ˜å¼é…ç½®åˆ‡æ¢é¢†åŸŸ
> ğŸ“¦ **è®­ç»ƒæ ¼å¼å¯¼å‡º** SFT / DPO / HuggingFace ä¸€é”®å‘å¸ƒ

## å­åŒ…ä¸€è§ˆ

| åŒ…å | åŠŸèƒ½ | CLI | MCP | æµ‹è¯• |
|------|------|-----|-----|------|
| [**knowlyr-core**](packages/core/) | å…±äº«æ¨¡å‹ + Gym åè®® (AgentEnv, TimeStep, Wrapper, Registry) | â€” | â€” | 96 |
| [**knowlyr-sandbox**](packages/sandbox/) | Docker æ²™ç®±æ‰§è¡Œç¯å¢ƒ + SandboxEnv é€‚é…å™¨ | `knowlyr-sandbox` | 4 Tools | 65 |
| [**knowlyr-recorder**](packages/recorder/) | Agent è½¨è¿¹å½•åˆ¶ã€æ ¼å¼è½¬æ¢ã€é€‚é…å™¨æ³¨å†Œè¡¨ | `knowlyr-recorder` | 3 Tools | 62 |
| [**knowlyr-reward**](packages/reward/) | è¿‡ç¨‹çº§ Rubric Reward (è§„åˆ™å±‚ + LLM-as-Judge)ï¼Œå¤šé¢†åŸŸ ToolClassifier | `knowlyr-reward` | 4 Tools | 131 |
| [**knowlyr-hub**](packages/hub/) | Pipeline ç¼–æ’ã€è½¨è¿¹æ”¶é›† (collect)ã€æ•°æ®é›†å¯¼å‡º (SFT/DPO/HuggingFace) | `knowlyr-hub` | 5 Tools | 73 |

æ¯ä¸ªåŒ…**ç‹¬ç«‹å®‰è£…ã€ç‹¬ç«‹ä½¿ç”¨**ï¼Œsandbox / recorder / reward ä¸‰è€…æ— äº¤å‰ä¾èµ–ã€‚Hub é€šè¿‡å¯é€‰ä¾èµ–ä¸²è”å…¨éƒ¨åŒ…ã€‚

## æ¶æ„

```mermaid
graph TD
    C["knowlyr-core<br/>AgentEnv Â· TimeStep Â· Wrapper Â· Registry"] -.->|åè®®+æ¨¡å‹| S
    C -.-> R
    C -.-> W
    C -.-> H
    T["Task<br/>JSONL / SWE-bench"] --> S["knowlyr-sandbox<br/>SandboxEnv Â· Docker éš”ç¦»æ‰§è¡Œ"]
    S -->|raw log| R["knowlyr-recorder<br/>é€‚é…å™¨ â†’ æ ‡å‡†åŒ–è½¨è¿¹"]
    R -->|Trajectory| W["knowlyr-reward<br/>ToolClassifier â†’ è¿‡ç¨‹çº§ Reward"]
    W -->|scored trajectory| H["knowlyr-hub<br/>collect() Â· Pipeline ç¼–æ’"]
    H --> O1["SFT æ•°æ®é›†"]
    H --> O2["DPO åå¥½å¯¹"]
    H --> O3["HuggingFace å‘å¸ƒ"]

    style C fill:#2d333b,color:#adbac7,stroke:#444c56
```

## å®‰è£…

```bash
pip install knowlyr-hub[all]   # å®‰è£…å…¨éƒ¨åŒ…
```

<details>
<summary>ğŸ“¦ æŒ‰éœ€å®‰è£…å•ä¸ªåŒ…</summary>

```bash
pip install knowlyr-core       # å…±äº«æ¨¡å‹ï¼ˆå…¶ä»–åŒ…ä¼šè‡ªåŠ¨ä¾èµ–ï¼‰
pip install knowlyr-sandbox    # æ²™ç®±æ‰§è¡Œ
pip install knowlyr-recorder   # è½¨è¿¹å½•åˆ¶
pip install knowlyr-reward     # Reward è¯„åˆ†
pip install knowlyr-hub        # Pipeline ç¼–æ’

# Reward LLM-as-Judge éœ€è¦é¢å¤–å®‰è£…
pip install knowlyr-reward[llm]   # anthropic + openai
```

</details>

## å¿«é€Ÿå¼€å§‹

### CLI

```bash
# 1. è½¬æ¢ Agent æ—¥å¿—ä¸ºæ ‡å‡†è½¨è¿¹
knowlyr-recorder convert agent_log.jsonl -f openhands -o trajectory.json

# 2. å¯¹è½¨è¿¹è®¡ç®— Rewardï¼ˆé»˜è®¤ coding é¢†åŸŸï¼‰
knowlyr-reward score trajectory.json

# 3. å¯¹æµè§ˆå™¨ Agent è½¨è¿¹è¯„åˆ†ï¼ˆæŒ‡å®šé¢†åŸŸï¼‰
knowlyr-reward score browser_traj.json --domain browser

# 4. ä½¿ç”¨è‡ªå®šä¹‰ DomainProfile è¯„åˆ†
knowlyr-reward score traj.json --domain examples/browser_profile.json

# 5. æ¯”è¾ƒåŒä¸€ä»»åŠ¡çš„å¤šæ¡è½¨è¿¹
knowlyr-reward compare traj_a.json traj_b.json

# 6. Hub: å¤„ç†å•ä¸ªæ—¥å¿— â†’ å¸¦ Reward çš„æ ‡å‡†è½¨è¿¹
knowlyr-hub process agent_log.jsonl -f openhands --save

# 7. Hub: æ‰¹é‡å¤„ç†æ—¥å¿—ç›®å½•
knowlyr-hub process-batch ./logs/ -f sweagent -p "*.json"

# 8. å¯¼å‡ºä¸ºè®­ç»ƒæ ¼å¼
knowlyr-hub export --format sft -t output/trajectories.jsonl -o sft_data.jsonl
knowlyr-hub export --format dpo -t output/trajectories.jsonl -p output/preferences.jsonl -o dpo_data.jsonl

# 9. å‘å¸ƒåˆ° HuggingFace
knowlyr-hub publish -t output/trajectories.jsonl --repo-id user/my-dataset --generate-card
```

### Python API

```python
from trajectoryhub import Pipeline, PipelineConfig, Trajectory

# ä»æ—¥å¿—ç”Ÿæˆå¸¦è¯„åˆ†çš„è½¨è¿¹
pipeline = Pipeline(PipelineConfig(output_dir="./output"))
traj: Trajectory = pipeline.run_from_log("agent.jsonl", "openhands")
print(f"Reward: {traj.reward:.3f}, Steps: {traj.total_steps}")

# æ‰¹é‡å¤„ç†
trajectories = pipeline.run_batch_from_logs("./logs/", "sweagent", "*.json")

# ç›´æ¥ä½¿ç”¨ Reward å¼•æ“
from agentreward import RewardEngine
engine = RewardEngine()
result = engine.score({"task": "Fix bug", "steps": [...], "outcome": {"success": True}})
print(f"Total: {result.total_score:.3f}")

# å¤šé¢†åŸŸ: ç”¨ Browser DomainProfile è¯„åˆ†
from knowlyrcore import load_domain_profile
from agentreward import RewardEngine

profile = load_domain_profile("browser_profile.json")
engine = RewardEngine(profile=profile)
result = engine.score(browser_trajectory_data)
```

<details>
<summary>ğŸ‹ï¸ Gym-Style API</summary>

## Gym-Style API

å€Ÿé‰´ [Gymnasium](https://github.com/Farama-Foundation/Gymnasium) / [BrowserGym](https://github.com/ServiceNow/BrowserGym) / [AgentGym](https://github.com/WooooDyy/AgentGym) è®¾è®¡ï¼Œæä¾›ç»Ÿä¸€çš„ç¯å¢ƒåè®®å’Œå¯ç»„åˆ Wrapperã€‚

### AgentEnv åè®®

æ‰€æœ‰ç¯å¢ƒï¼ˆDocker æ²™ç®±ã€æµè§ˆå™¨ã€API mockï¼‰å®ç°ç›¸åŒæ¥å£ï¼š

```python
from knowlyrcore.env import AgentEnv
from knowlyrcore.timestep import TimeStep

class MyEnv(AgentEnv):
    domain = "my_domain"

    def reset(self, *, task=None, seed=None) -> TimeStep:
        return TimeStep(observation="ready")

    def step(self, action: dict) -> TimeStep:
        return TimeStep(observation="result", terminated=(action["tool"] == "submit"))

    @property
    def available_tools(self):
        return ["observe", "act", "submit"]
```

### æ³¨å†Œä¸å‘ç°

```python
from knowlyrcore.registry import register, make, list_envs

register("my-project/my-env", MyEnv, domain="my_domain")

env = make("my-project/my-env")      # æŒ‰ ID åˆ›å»ºå®ä¾‹
envs = list_envs(domain="coding")    # æŒ‰é¢†åŸŸæŸ¥è¯¢
```

### Wrapper å¯ç»„åˆ

```python
from knowlyrcore.wrappers import MaxStepsWrapper, RewardWrapper, RecorderWrapper

env = make("knowlyr/sandbox")
env = MaxStepsWrapper(env, max_steps=50)           # é™åˆ¶æ­¥æ•°
env = RewardWrapper(env, reward_fn=my_reward_fn)   # æ³¨å…¥ reward
env = RecorderWrapper(env, agent_name="my-agent")  # å½•åˆ¶è½¨è¿¹

ts = env.reset(task=my_task)
while not ts.done:
    action = agent(ts.observation)
    ts = env.step(action)

trajectory = env.get_trajectory()   # RecorderWrapper æä¾›
```

å†…ç½® 4 ä¸ª Wrapperï¼š`MaxStepsWrapper` (æ­¥æ•°æˆªæ–­)ã€`TimeoutWrapper` (è¶…æ—¶æˆªæ–­)ã€`RewardWrapper` (reward æ³¨å…¥)ã€`RecorderWrapper` (è½¨è¿¹å½•åˆ¶)ã€‚

### collect() æ‰¹é‡æ”¶é›†

```python
from trajectoryhub import collect

trajs = collect(
    "knowlyr/sandbox",       # env ID æˆ– AgentEnv å®ä¾‹
    agent=my_agent,          # (observation) -> action dict
    n_episodes=10,
    max_steps=30,
    agent_name="my-agent",
    model_name="gpt-4o",
)
```

è¯¦è§ [`examples/gym_usage.py`](examples/gym_usage.py)ã€‚

</details>

## å¤šé¢†åŸŸæ”¯æŒ

é»˜è®¤ä¸º **coding** é¢†åŸŸï¼ˆCode Agent / SWE-benchï¼‰ï¼ŒåŒæ—¶æ”¯æŒ Browser Agentã€Data Analysis ç­‰ä»»æ„ tool-use agent é¢†åŸŸã€‚é€šè¿‡ `DomainProfile` å£°æ˜å¼é…ç½®ï¼Œå‘Šè¯‰æ¯ä¸ªåŒ…å½“å‰åœ¨å“ªä¸ªé¢†åŸŸè¿è¡Œã€‚

### å†…ç½®é¢†åŸŸ

| é¢†åŸŸ | Profile | è¯´æ˜ | é¢„å®šä¹‰å·¥å…· |
|------|---------|------|-----------|
| `coding` | `CODING_PROFILE` | Code Agent (é»˜è®¤) | read_file, edit_file, bash, grep, submit... |
| `browser` | `BROWSER_PROFILE` | Browser Agent | navigate, click, type_text, screenshot, scroll... |
| `generic` | `GENERIC_PROFILE` | é€šç”¨ (æ— é¢„å®šä¹‰å·¥å…·) | è§„åˆ™å±‚é€€åŒ–ä¸ºå¯å‘å¼æ¨¡å¼ |

<details>
<summary>ğŸ”§ è‡ªå®šä¹‰ DomainProfile</summary>

### DomainProfile ç»“æ„

```python
from knowlyrcore import DomainProfile, ToolSpec, ToolCategory, OutcomeSpec

profile = DomainProfile(
    domain="my_domain",
    display_name="My Custom Domain",
    tools=[
        ToolSpec(name="observe", category=ToolCategory.READ, stateful_key="target"),
        ToolSpec(name="act", category=ToolCategory.WRITE, stateful_key="target"),
        ToolSpec(name="search", category=ToolCategory.SEARCH),
        ToolSpec(name="done", category=ToolCategory.SUBMIT),
    ],
    outcome_spec=OutcomeSpec(success_field="success", score_field="score"),
    default_rubric_weights={
        "goal_progress": 0.35,
        "tool_selection": 0.20,
        "param_correctness": 0.20,
        "info_utilization": 0.10,
        "non_redundancy": 0.15,
    },
)
```

å·¥å…·ç±»åˆ« (`ToolCategory`)ï¼š`READ` / `WRITE` / `SEARCH` / `EXECUTE` / `NAVIGATE` / `SUBMIT` / `THINK`

### è‡ªå®šä¹‰é€‚é…å™¨

Recorder æä¾›é€‚é…å™¨æ³¨å†Œè¡¨ï¼Œæ”¯æŒæ³¨å†Œè‡ªå®šä¹‰ Agent æ¡†æ¶é€‚é…å™¨ï¼š

```python
from agentrecorder.adapters import BaseAdapter, register_adapter

class MyAgentAdapter(BaseAdapter):
    domain = "browser"

    def parse(self, log_path: str) -> Trajectory:
        ...  # è§£æä½ çš„ Agent æ—¥å¿—

    def validate(self, log_path: str) -> bool:
        ...  # éªŒè¯æ—¥å¿—æ ¼å¼

register_adapter("my-agent", MyAgentAdapter)
```

è¯¦è§ [`examples/browser_profile.json`](examples/browser_profile.json) å’Œ [`examples/browser_trajectory.json`](examples/browser_trajectory.json)ã€‚

</details>

## MCP Server

æ¯ä¸ªå­åŒ…æä¾›ç‹¬ç«‹çš„ MCP Serverï¼Œå…± 16 ä¸ª Toolsï¼š

| Server | å¯åŠ¨æ–¹å¼ |
|--------|---------|
| knowlyr-sandbox | `python -m agentsandbox.mcp_server` |
| knowlyr-recorder | `python -m agentrecorder.mcp_server` |
| knowlyr-reward | `python -m agentreward.mcp_server` |
| knowlyr-hub | `python -m trajectoryhub.mcp_server` |

<details>
<summary>16 Tools è¯¦æƒ…</summary>

- **sandbox**: `create_sandbox`, `execute_tool`, `reset_sandbox`, `replay_trajectory`
- **recorder**: `convert_log`, `validate_log`, `get_schema`
- **reward**: `score_trajectory`, `compare_trajectories`, `build_preferences`, `list_rubrics`
- **hub**: `run_pipeline`, `export_dataset`, `process_log`, `process_logs_batch`, `pipeline_status`

</details>

## å¼€å‘

```bash
git clone https://github.com/liuxiaotong/knowlyr-agent.git
cd knowlyr-agent

make install-dev        # å¼€å‘æ¨¡å¼å®‰è£…å…¨éƒ¨åŒ…
make test               # è¿è¡Œå…¨éƒ¨æµ‹è¯• (444 passed)
make test-sandbox       # å•ç‹¬æµ‹è¯•æŸä¸ªåŒ…
make test-integration   # è·¨åŒ…é›†æˆæµ‹è¯• (17 tests)
make lint               # ruff æ£€æŸ¥
make build              # æ„å»ºå…¨éƒ¨åŒ…
```

## Data Pipeline ç”Ÿæ€

æœ¬é¡¹ç›®æ˜¯ [knowlyr æ•°æ®å·¥ç¨‹ç”Ÿæ€](https://github.com/liuxiaotong) çš„ Agent å·¥å…·é“¾éƒ¨åˆ†ï¼š

### ç”Ÿæ€é¡¹ç›®

| å±‚ | é¡¹ç›® | PyPI åŒ… | è¯´æ˜ | ä»“åº“ |
|---|---|---|---|---|
| æƒ…æŠ¥ | **AI Dataset Radar** | knowlyr-radar | æ•°æ®é›†ç«äº‰æƒ…æŠ¥ã€è¶‹åŠ¿åˆ†æ | [GitHub](https://github.com/liuxiaotong/ai-dataset-radar) |
| åˆ†æ | **DataRecipe** | knowlyr-datarecipe | é€†å‘åˆ†æã€Schema æå–ã€æˆæœ¬ä¼°ç®— | [GitHub](https://github.com/liuxiaotong/data-recipe) |
| ç”Ÿäº§ | **DataSynth** | knowlyr-datasynth | LLM æ‰¹é‡åˆæˆã€ç§å­æ•°æ®æ‰©å…… | [GitHub](https://github.com/liuxiaotong/data-synth) |
| ç”Ÿäº§ | **DataLabel** | knowlyr-datalabel | è½»é‡æ ‡æ³¨å·¥å…·ã€å¤šæ ‡æ³¨å‘˜åˆå¹¶ | [GitHub](https://github.com/liuxiaotong/data-label) |
| è´¨æ£€ | **DataCheck** | knowlyr-datacheck | è§„åˆ™éªŒè¯ã€é‡å¤æ£€æµ‹ã€åˆ†å¸ƒåˆ†æ | [GitHub](https://github.com/liuxiaotong/data-check) |
| è´¨æ£€ | **ModelAudit** | knowlyr-modelaudit | è’¸é¦æ£€æµ‹ã€æ¨¡å‹æŒ‡çº¹ã€èº«ä»½éªŒè¯ | [GitHub](https://github.com/liuxiaotong/model-audit) |
| Agent | **knowlyr-agent** | knowlyr-sandbox / recorder / reward / hub | æ²™ç®± + è½¨è¿¹å½•åˆ¶ + Reward + ç¼–æ’ | You are here |

<details>
<summary>ğŸ—ºï¸ ç”Ÿæ€æ¶æ„å›¾</summary>

```mermaid
graph LR
    Radar["ğŸ” Radar<br/>æƒ…æŠ¥å‘ç°"] --> Recipe["ğŸ“‹ Recipe<br/>é€†å‘åˆ†æ"]
    Recipe --> Synth["ğŸ”„ Synth<br/>æ•°æ®åˆæˆ"]
    Recipe --> Label["ğŸ·ï¸ Label<br/>æ•°æ®æ ‡æ³¨"]
    Synth --> Check["âœ… Check<br/>æ•°æ®è´¨æ£€"]
    Label --> Check
    Check --> Audit["ğŸ”¬ Audit<br/>æ¨¡å‹å®¡è®¡"]
    Audit --> Hub["ğŸ¯ Hub<br/>ç¼–æ’å±‚"]
    Hub --> Sandbox["ğŸ“¦ Sandbox<br/>æ‰§è¡Œæ²™ç®±"]
    Sandbox --> Recorder["ğŸ“¹ Recorder<br/>è½¨è¿¹å½•åˆ¶"]
    Recorder --> Reward["â­ Reward<br/>è¿‡ç¨‹æ‰“åˆ†"]
    style Hub fill:#0969da,color:#fff,stroke:#0969da
    style Sandbox fill:#0969da,color:#fff,stroke:#0969da
    style Recorder fill:#0969da,color:#fff,stroke:#0969da
    style Reward fill:#0969da,color:#fff,stroke:#0969da
```

</details>

## License

MIT

---

<div align="center">
<sub><a href="https://github.com/liuxiaotong">knowlyr</a> æ•°æ®å·¥ç¨‹ç”Ÿæ€ Â· Agent è½¨è¿¹æ•°æ®å·¥ç¨‹</sub>
</div>
